{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scrapper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnaCWu5G12c0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "cf1ee333-a8e9-4d6c-9d78-60b20f4df041"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "# !cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (80.0.3987.87-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 97 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u19byMJru1N2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.select import Select\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import NoSuchElementException, WebDriverException\n",
        "from selenium.webdriver.firefox.options import Options\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import functools\n",
        "import re\n",
        "import requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvDZ_zPb2eo_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "24851ee5-8a5b-4387-cbfe-0a0ba23ebbc7"
      },
      "source": [
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: use options instead of chrome_options\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26mryj55vyHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_stats_frame(df,teams,player_id, team_ind ,player_name, columns, drop_indexes, drop_cols, id_vars, tm_id): \n",
        "    df.drop(df.tail(1).index,inplace=True)\n",
        "    df.iloc[:,team_ind] = teams\n",
        "    df = df.drop(df.columns[drop_indexes], axis = 1)\n",
        "    df.columns = columns\n",
        "    if not(drop_cols == []):\n",
        "        df = df.drop(drop_cols, axis = 1)\n",
        "    df.insert(0,\"tm_Id\", tm_id)\n",
        "    df.insert(1,\"Player_Id\", player_id)\n",
        "    df.insert(2,\"Name\", player_name)\n",
        "    df_long = pd.melt(df, id_vars = id_vars, var_name = \"Attribute\")\n",
        "    return df_long"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-4xMQ9m3Ka1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_if_exists(dest):\n",
        "    result = True\n",
        "    try:\n",
        "        open(dest)\n",
        "    except IOError:\n",
        "        result = False\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYT5b--R3YUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_empty_df(file_dest, columns):\n",
        "    data_frame = pd.DataFrame(columns=columns)\n",
        "    data_frame.to_csv(file_dest)\n",
        "\n",
        "\n",
        "def create_csv_dfs():\n",
        "    create_empty_df(\"./Scrapped_Data/injuries.csv\", columns = [\"sofifa_id\",\"Name\",\"Reason\",\"Start Date\",\"End Date\"])\n",
        "    create_empty_df(\"./Scrapped_Data/trophies.csv\", columns = [\"sofifa_id\",\"Name\",\"Competition\",\"Trophy\",\"Season\"])\n",
        "    create_empty_df(\"./Scrapped_Data/markval.csv\", columns = ['Name', 'Club', 'League', 'Season', 'Market Value', \"tm_Id\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gNEF-XdkzCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sign_in(driver):\n",
        "    driver.get(\"https://www.instagram.com/\")\n",
        "    username = \"grno53\"\n",
        "    password = \"grnogrno22\"\n",
        "    time.sleep(10)\n",
        "    username_field = driver.find_elements_by_css_selector(\".zyHYP\")[0]\n",
        "    pass_field = driver.find_elements_by_css_selector(\".zyHYP\")[1]\n",
        "    username_field.send_keys(username)\n",
        "    pass_field.send_keys(password)\n",
        "    sign_in_button = driver.find_elements_by_css_selector(\".y3zKF , .y3zKF ._4EzTm\")[0]\n",
        "    sign_in_button.click()\n",
        "    time.sleep(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv3IDAFQv8pJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Player:\n",
        "    def __init__(self, id, link, driver, df_path, stats_path, nat_stats_path, transfers_path, name):\n",
        "        # self.name = \"no_info\"\n",
        "        self.driver = driver\n",
        "        self.id = id\n",
        "        self.link = link\n",
        "        self.info_df = None\n",
        "        self.followers = None\n",
        "        self.df_path = df_path\n",
        "        self.stats_path = stats_path\n",
        "        self.nat_stats_path = nat_stats_path\n",
        "        self.transfers_path = transfers_path\n",
        "        self.position = None\n",
        "        self.tm_Id = None\n",
        "        self.name = name\n",
        "        print(self.id)\n",
        "        self.get_tm_id()\n",
        "        self.get_info()\n",
        "        self.get_followers()\n",
        "        self.data_to_append()\n",
        "        self.get_player_stats()\n",
        "        self.get_nat_stats()\n",
        "        self.get_transfers()\n",
        "\n",
        "    def get_transfers(self):\n",
        "        print(\"trying to get player's transfers\")\n",
        "        transfers = pd.DataFrame(columns=['Player_Id', \"tm_Id\", 'Name', 'From', 'To', 'Fee', 'Market Value', 'Season', 'Date'])\n",
        "        try:\n",
        "            link = self.link.replace(\"profil\",\"transfers\")\n",
        "            self.driver.get(link)\n",
        "            bs_obj = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
        "            rows = bs_obj.find_all('table')[0].find('tbody').find_all('tr',{\"class\":\"zeile-transfer\"})\n",
        "            for row in rows:\n",
        "                cols = row.find_all('td')\n",
        "                data = {\n",
        "                    \"Player_Id\": self.id,\n",
        "                    \"tm_Id\": self.tm_Id,\n",
        "                    \"Name\": self.name,\n",
        "                    \"From\": cols[5].get_text(),\n",
        "                    \"To\": cols[9].get_text(),\n",
        "                    \"Fee\": cols[11].get_text(),\n",
        "                    \"Market Value\": cols[10].get_text(),\n",
        "                    \"Season\": cols[0].get_text(),\n",
        "                    \"Date\": cols[1].get_text()\n",
        "                }\n",
        "                transfers = transfers.append(data, ignore_index=True)\n",
        "                transfers.set_index(\"tm_Id\", inplace=True, drop=False)\n",
        "                transfers.to_csv(self.transfers_path, mode = \"a\", header= False)\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "        # self.transfers_df = transfers\n",
        "\n",
        "    def go_detailed_page(self):\n",
        "        detailed = self.driver.find_elements_by_css_selector(\".kartei-button-body\")[1]\n",
        "        self.driver.execute_script(\"arguments[0].click();\", detailed)\n",
        "        time.sleep(5)\n",
        "\n",
        "    def get_tm_id(self):\n",
        "        digits = re.findall(r\"\\d\", self.link)\n",
        "        self.tm_Id = functools.reduce(lambda a,b : a+b,digits)\n",
        "\n",
        "    def get_info(self):\n",
        "        print(\"trying to get information about the player\")\n",
        "        try:\n",
        "            self.driver.get(self.link)\n",
        "            bs_obj = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
        "            # name = bs_obj.find_all('h1')[0].get_text()\n",
        "            table = bs_obj.find_all('table')[0]\n",
        "            df = pd.read_html(str(table))[0]\n",
        "            df.columns = [\"Key\", \"Value\"]\n",
        "            self.info_df = df\n",
        "            # self.name = name\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "\n",
        "    def get_followers(self):\n",
        "        print(\"trying to get information about the player's followers\")\n",
        "        insta_xpath = \"//*[@title='Instagram']\"\n",
        "        insta_link = None\n",
        "        followers = None\n",
        "        try:\n",
        "            insta_link = self.driver.find_element_by_xpath(insta_xpath).get_attribute(\"href\")\n",
        "            if not(insta_link is None):\n",
        "                pat = r'.com?\\/(.*)/.*'\n",
        "                username = re.findall(pat, insta_link)[0]\n",
        "                def_url = \"https://www.instagram.com/<username>/?__a=1\"\n",
        "                url = def_url.replace(\"<username>\", username)\n",
        "                r = requests.get(url = url) \n",
        "                data = r.json()\n",
        "                followers = data[\"graphql\"][\"user\"][\"edge_followed_by\"][\"count\"]\n",
        "        except Exception as e:\n",
        "            print(\"no info about followers, trying to visit the page\")\n",
        "            print(str(e))\n",
        "            try:\n",
        "                insta_link = self.driver.find_element_by_xpath(insta_xpath).get_attribute(\"href\")\n",
        "                if not(insta_link is None):\n",
        "                    self.driver.get(insta_link)\n",
        "                    time.sleep(2)\n",
        "                    bs_obj = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
        "                    followers = bs_obj.find_all(\"span\", class_=\"g47SY\")[1][\"title\"]\n",
        "            except Exception as e:\n",
        "                print(\"another exception, catching it\")\n",
        "                print(str(e))\n",
        "        finally:\n",
        "            if(followers is None):\n",
        "                print(\"nothing found\")\n",
        "                followers = \"no info\"\n",
        "            else:\n",
        "                print(\"number of followers\",followers)\n",
        "        self.followers = followers\n",
        "\n",
        "    def extract_cell(self, key):\n",
        "        result = None\n",
        "        df = self.info_df\n",
        "        try:\n",
        "            result = df[df[\"Key\"] == key][\"Value\"].values[0]\n",
        "        except:\n",
        "            print(\"the player does not have \" + str(key))\n",
        "            result = \"no_info\"\n",
        "        return result\n",
        "\n",
        "    def data_to_append(self):\n",
        "        try:\n",
        "            data = {\n",
        "                'Id': self.id,\n",
        "                'tm_Id': self.tm_Id,\n",
        "                'Name':  self.name,\n",
        "                'Team':  self.extract_cell(\"Current club:\"),\n",
        "                'Nationality':  self.extract_cell(\"Citizenship:\"),\n",
        "                'Date of Birth':  self.extract_cell(\"Date of birth:\"),\n",
        "                'Height':  self.extract_cell(\"Height:\"),\n",
        "                'Strong Foot':  self.extract_cell(\"Foot:\"),\n",
        "                'Position':  self.extract_cell(\"Position:\"),\n",
        "                'Joined':  self.extract_cell(\"Joined:\"),\n",
        "                'Contract Expires':  self.extract_cell(\"Contract expires:\"),\n",
        "                'Followers':  self.followers\n",
        "            }\n",
        "            df = pd.DataFrame(columns = ['Id','tm_Id','Name', 'Team', 'Nationality', 'Date of Birth', 'Height', 'Strong Foot', 'Position', 'Joined', 'Contract Expires', 'Followers'])\n",
        "            df = df.append(data, ignore_index = True)\n",
        "            df.set_index(\"tm_Id\", inplace=True, drop=False)\n",
        "            df.to_csv(self.df_path, mode = \"a\", header= False)\n",
        "            self.position = data[\"Position\"]\n",
        "            self.data = data\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "        # self.position = data[\"Position\"]\n",
        "        # self.data = data\n",
        "        # self.df = df\n",
        "\n",
        "    def get_player_stats(self):\n",
        "        print(\"trying to get the player's statistics\")\n",
        "        df_long = None\n",
        "        teams_xpath = \"//*[contains(concat( ' ', @class, ' ' ), concat( ' ', 'zentriert', ' ' ))]//img\"\n",
        "        # position_xpath = '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"dataValue\", \" \" ))]'\n",
        "        try:\n",
        "            stats_link = self.link.replace(\"profil\",\"leistungsdatendetails\")\n",
        "            self.driver.get(stats_link)\n",
        "            self.go_detailed_page()\n",
        "            get_name = lambda input: input.get_attribute('alt')\n",
        "            teams = self.driver.find_elements_by_xpath(teams_xpath)\n",
        "            teams = list(map(get_name, teams))\n",
        "            bs_obj = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
        "            table = bs_obj.find_all('table')[1]\n",
        "            df = pd.read_html(str(table))[0]\n",
        "            position = self.extract_cell(\"Position:\")\n",
        "            if(position == \"Goalkeeper\"):\n",
        "                columns = [\"Season\",\"Team\",\"Competition\",\"Squad\",\n",
        "                    \"Appearances\",\"PPG\",\"Goals\",\"Own goals\",\"Substitutions on\",\n",
        "                    \"Substitutions off\",\"Yellow Cards\",\"Second yellow cards\",\"Red cards\",\n",
        "                    \"Goals conceded\",\"Clean sheets\",\"Minutes played\"]\n",
        "                drop_indexes = [3,17]\n",
        "                drop_cols = [\"Goals\"]\n",
        "            else:\n",
        "                columns = [\"Season\",\"Team\",\"Competition\",\"Squad\",\n",
        "                \"Appearances\",\"PPG\",\"Goals\",\"Assists\",\"Own goals\",\"Substitutions on\",\n",
        "                \"Substitutions off\",\"Yellow Cards\",\"Second yellow cards\",\"Red cards\",\n",
        "                \"Penalty goals\",\"Minutes per goal\",\"Minutes played\"]\n",
        "                drop_indexes = [3,18]\n",
        "                drop_cols = []\n",
        "            id_vars = [\"Player_Id\",\"tm_Id\",\"Name\",\"Team\",\"Season\",\"Competition\"]\n",
        "            df_long = clean_stats_frame(df = df, teams = teams, team_ind = 1, player_id = self.id,\n",
        "            player_name = self.name, columns = columns, drop_indexes = drop_indexes,\n",
        "            drop_cols = drop_cols, id_vars = id_vars, tm_id = self.tm_Id)\n",
        "            df_long.set_index(\"tm_Id\", inplace=True, drop=False)\n",
        "            df_long.to_csv(self.stats_path, mode = \"a\", header= False)\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "\n",
        "    def get_nat_stats(self):\n",
        "        print(\"trying to get the player's national team statistics\")\n",
        "        nat_team_xpath = '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"tooltipstered\", \" \" ))]'\n",
        "        df_long = None\n",
        "        try:\n",
        "            nat_link = self.link.replace(\"profil\",\"nationalmannschaft\")\n",
        "            self.driver.get(nat_link)\n",
        "            self.go_detailed_page()\n",
        "            nat_team = self.driver.find_element_by_xpath(nat_team_xpath).text\n",
        "            bs_obj = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
        "            table = bs_obj.find_all('table')[2]\n",
        "            df = pd.read_html(str(table))[0]\n",
        "            position = self.extract_cell(\"Position:\")\n",
        "            if(position == \"Goalkeeper\"):\n",
        "                columns = [\"National Team\",\"Competition\",\n",
        "                        \"Appearances\",\"Goals\",\"Own goals\",\"Substitutions on\",\n",
        "                        \"Substitutions off\",\"Yellow Cards\",\"Second yellow cards\",\"Red cards\",\n",
        "                        \"Goals conceded\",\"Clean sheets\",\"Minutes played\"]\n",
        "                drop_indexes = [13]\n",
        "                drop_cols = [\"Goals\"]\n",
        "            else:\n",
        "                drop_indexes = [14]\n",
        "                columns = [\"National Team\",\"Competition\",\"Squad\",\n",
        "                        \"Goals\",\"Assists\",\"Own goals\",\"Substitutions on\",\n",
        "                        \"Substitutions off\",\"Yellow Cards\",\"Second yellow cards\",\"Red cards\",\n",
        "                        \"Penalty goals\",\"Minutes per goal\",\"Minutes played\"]\n",
        "                drop_cols = []\n",
        "            id_vars = [\"Player_Id\",\"tm_Id\",\"Name\",\"National Team\",\"Competition\"]\n",
        "            df_long = clean_stats_frame(df = df, teams = nat_team, team_ind = 0, player_id = self.id,\n",
        "            player_name = self.name, columns = columns, drop_indexes = drop_indexes,\n",
        "            drop_cols = drop_cols, id_vars = id_vars, tm_id = self.tm_Id)\n",
        "            df_long.set_index(\"tm_Id\", inplace=True, drop=False)\n",
        "            df_long.to_csv(self.nat_stats_path, mode = \"a\", header= False)\n",
        "        except Exception as e:\n",
        "            print(str(e))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h701IcAjwDf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "player_links = pd.read_csv(\"/content/drive/My Drive/Capstone/Prerequisite Data/playerlinks.csv\")['Player_url']\n",
        "player_names = pd.read_csv(\"/content/drive/My Drive/Capstone/Prerequisite Data/playerlinks.csv\")['Player_url']\n",
        "# a = pd.read_csv(\"/content/drive/My Drive/Capstone/Prerequisite Data/playerlinks.csv\")\n",
        "# a.to_csv('data.csv')\n",
        "# !cp data.csv \"drive/My Drive/Capstone/Scrapped_Data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73k50zJlnVFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def start_scrapping(driver, start, end, player_links):\n",
        "    dest_cols = {\n",
        "        \"drive/My Drive/Capstone/Scrapped_Data/Players.csv\" : ['Id','tm_Id','Name', 'Team', 'Nationality', 'Date of Birth', 'Height', 'Strong Foot', 'Position', 'Joined', 'Contract Expires', 'Followers'],\n",
        "        \"drive/My Drive/Capstone/Scrapped_Data/stats.csv\" : ['Player_Id', 'tm_Id', 'Name', 'Team', 'Season', 'Competition', 'Attribute','value'],\n",
        "        \"drive/My Drive/Capstone/Scrapped_Data/natstats.csv\" : [\"Player_Id\", \"tm_Id\", \"Name\",\"National Team\",\"Competition\", \"Attribute\", \"value\"],\n",
        "        \"drive/My Drive/Capstone/Scrapped_Data/Transfers.csv\" : ['Player_Id', \"tm_Id\", 'Name', 'From', 'To', 'Fee', 'Market Value', 'Season', 'Date']\n",
        "    }\n",
        "    for dest,cols  in dest_cols.items():\n",
        "        if(not(check_if_exists(dest = dest))):\n",
        "            create_empty_df(file_dest = dest, columns = cols)\n",
        "\n",
        "    sign_in(driver)\n",
        "    for id in range(start, end):\n",
        "        player = None\n",
        "        try:\n",
        "            link = player_links[id]\n",
        "            name = player_names[id]\n",
        "            dests = list(dest_cols.keys())\n",
        "            player = Player(id = id, link = link, driver = driver, df_path = dests[0], stats_path = dests[1],\n",
        "            nat_stats_path = dests[2], transfers_path = dests[3], name = name)\n",
        "        except Exception as e:\n",
        "            print(\"The exception message\", str(e))\n",
        "            break\n",
        "        del player\n",
        "    driver.quit()\n",
        "    print(\"Finished scrapping\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI3MBS-n2w_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "a62cb7a0-cd87-4810-aec4-eba1a996f23a"
      },
      "source": [
        "start_scrapping(driver, start = 10000, end = 10200, player_links = player_links)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "trying to get information about the player\n",
            "trying to get information about the player's followers\n",
            "no info about followers, trying to visit the page\n",
            "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@title='Instagram']\"}\n",
            "  (Session info: headless chrome=80.0.3987.87)\n",
            "\n",
            "another exception, catching it\n",
            "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@title='Instagram']\"}\n",
            "  (Session info: headless chrome=80.0.3987.87)\n",
            "\n",
            "nothing found\n",
            "the player does not have Height:\n",
            "the player does not have Foot:\n",
            "trying to get the player's statistics\n",
            "trying to get the player's national team statistics\n",
            "list index out of range\n",
            "trying to get player's transfers\n",
            "10001\n",
            "trying to get information about the player\n",
            "trying to get information about the player's followers\n",
            "no info about followers, trying to visit the page\n",
            "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@title='Instagram']\"}\n",
            "  (Session info: headless chrome=80.0.3987.87)\n",
            "\n",
            "another exception, catching it\n",
            "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@title='Instagram']\"}\n",
            "  (Session info: headless chrome=80.0.3987.87)\n",
            "\n",
            "nothing found\n",
            "trying to get the player's statistics\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}